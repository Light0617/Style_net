{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libs import vgg16\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import reset_default_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_img(content_og, style_og):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    axs[0].imshow(content_og)\n",
    "    axs[0].set_title('Content Image')\n",
    "    axs[0].grid('off')\n",
    "    axs[1].imshow(style_og)\n",
    "    axs[1].set_title('Style Image')\n",
    "    axs[1].grid('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3.amazonaws.com/cadl/models/vgg16.tfmodel\n",
      "Downloaded 211.25/527.80 MB\r"
     ]
    }
   ],
   "source": [
    "net = vgg16.get_vgg_model()\n",
    "device = '/cpu:0'\n",
    "#create a graph\n",
    "g = tf.Graph()\n",
    "with tf.Session(graph=g) as sess, g.device(device):\n",
    "    tf.import_graph_def(net['graph_def'], name='net')\n",
    "    names = [op.name for op in g.get_operations()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_og = plt.imread('pic/farm.jpg')\n",
    "style_og = plt.imread('pic/yell.jpg')\n",
    "show_img(content_og, style_og )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_img0 = vgg16.preprocess(content_og)\n",
    "content_img = content_img0[np.newaxis]\n",
    "style_img0 = vgg16.preprocess(style_og)\n",
    "style_img = style_img0[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grab a placeholder for the input and output of the network\n",
    "x = g.get_tensor_by_name(names[0] + \":0\")\n",
    "softmax = g.get_tensor_by_name(names[-2] + \":0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess, g.device(device):\n",
    "    content_layer = 'net/conv4_2/conv4_2:0'\n",
    "    content_features = g.get_tensor_by_name(content_layer).eval(\n",
    "            session=sess,\n",
    "            feed_dict={x: content_img,\n",
    "                'net/dropout_1/random_uniform:0': [[1.0] * 4096],\n",
    "                'net/dropout/random_uniform:0': [[1.0] * 4096]\n",
    "            })\n",
    "print(content_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_layers = ['net/conv1_1/conv1_1:0',\n",
    "                'net/conv2_1/conv2_1:0',\n",
    "                'net/conv3_1/conv3_1:0',\n",
    "                'net/conv4_1/conv4_1:0',\n",
    "                'net/conv5_1/conv5_1:0']\n",
    "style_activations = []\n",
    "\n",
    "with tf.Session(graph=g) as sess, g.device(device):\n",
    "    for style_i in style_layers:\n",
    "        style_activation_i = g.get_tensor_by_name(style_i).eval(\n",
    "            feed_dict={\n",
    "                x: style_img,\n",
    "                'net/dropout_1/random_uniform:0': [[1.0] * 4096],\n",
    "                'net/dropout/random_uniform:0': [[1.0] * 4096]})\n",
    "        style_activations.append(style_activation_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_features = []\n",
    "for style_activation_i in style_activations:\n",
    "    s_i = np.reshape(style_activation_i, [-1, style_activation_i.shape[-1]])\n",
    "    gram_matrix = np.matmul(s_i.T, s_i) / s_i.size\n",
    "    style_features.append(gram_matrix.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_default_graph()\n",
    "g = tf.Graph()\n",
    "vgg = vgg16.get_vgg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess, g.device('/cpu:0'):\n",
    "    net_input = tf.Variable(content_img)\n",
    "    tf.import_graph_def(\n",
    "        net['graph_def'],\n",
    "        name='net',\n",
    "        input_map={'images:0': net_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess, g.device('/cpu:0'):\n",
    "    content_loss = tf.nn.l2_loss((g.get_tensor_by_name(content_layer) -\n",
    "                                 content_features) /\n",
    "                                 content_features.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess, g.device('/cpu:0'):\n",
    "    style_loss = np.float32(0.0)\n",
    "    for style_layer_i, style_gram_i in zip(style_layers, style_features):\n",
    "        layer_i = g.get_tensor_by_name(style_layer_i)\n",
    "        layer_shape = layer_i.get_shape().as_list()\n",
    "        layer_size = layer_shape[1] * layer_shape[2] * layer_shape[3]\n",
    "        layer_flat = tf.reshape(layer_i, [-1, layer_shape[3]])\n",
    "        gram_matrix = tf.matmul(tf.transpose(layer_flat), layer_flat) / layer_size\n",
    "        style_loss = tf.add(style_loss, tf.nn.l2_loss((gram_matrix - style_gram_i) / np.float32(style_gram_i.size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    h, w = x.get_shape().as_list()[1], x.get_shape().as_list()[1]\n",
    "    dx = tf.square(x[:, :h-1, :w-1, :] - x[:, :h-1, 1:, :])\n",
    "    dy = tf.square(x[:, :h-1, :w-1, :] - x[:, 1:, :w-1, :])\n",
    "    return tf.reduce_sum(tf.pow(dx + dy, 1.25))\n",
    "\n",
    "with tf.Session(graph=g) as sess, g.device('/cpu:0'):\n",
    "    tv_loss = total_variation_loss(net_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess, g.device('/cpu:0'):\n",
    "    loss = 0.1 * content_loss + 5.0 * style_loss + 0.01 * tv_loss\n",
    "    optimizer = tf.train.AdamOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess, g.device('/cpu:0'):\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # map input to noise\n",
    "    n_iterations = 60\n",
    "    og_img = net_input.eval()\n",
    "    imgs = []\n",
    "    for it_i in range(n_iterations):\n",
    "        _, this_loss, synth = sess.run([optimizer, loss, net_input],\n",
    "                feed_dict={\n",
    "                    'net/dropout_1/random_uniform:0':\n",
    "                        np.ones(g.get_tensor_by_name(\n",
    "                        'net/dropout_1/random_uniform:0').get_shape().as_list()),\n",
    "                    'net/dropout/random_uniform:0':\n",
    "                        np.ones(g.get_tensor_by_name(\n",
    "                        'net/dropout/random_uniform:0').get_shape().as_list())})\n",
    "        if it_i % 50 == 0:\n",
    "            print(\"%d: %f, (%f - %f)\" %\n",
    "            (it_i, this_loss, np.min(synth), np.max(synth)))\n",
    "            imgs.append(np.clip(synth[0], 0, 1))\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(22, 10))\n",
    "            ax[0].imshow(vgg16.deprocess(content_img0))\n",
    "            ax[0].set_title('content image')\n",
    "            ax[1].imshow(vgg16.deprocess(style_img0))\n",
    "            ax[1].set_title('style image')\n",
    "            ax[2].set_title('current synthesis')\n",
    "            ax[2].imshow(vgg16.deprocess(synth[0]))\n",
    "            plt.show()\n",
    "            fig.canvas.draw()\n",
    "    gif.build_gif(imgs, saveto='stylenet-bosch.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
